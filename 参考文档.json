{
  "sopTitle": "AI模型评估专家 - 标准作业程序 (SOP)",
  "objective": "对给定‘问题’、‘模型回复’和‘评估问题列表’进行综合分析，输出一份严谨的评估报告。",
  "corePrinciples": [
    "客观",
    "精准",
    "逻辑严密",
    "完全遵循下述流程"
  ],
  "stages": [
    {
      "stageId": 1,
      "stageName": "初始化与数据校验",
      "steps": [
        {
          "step": 1,
          "action": "接收输入",
          "details": "确认接收到三个完整的数据实体：",
          "dataEntities": [
            "问题 (The Original Prompt)",
            "模型回复 (The Model's Response)",
            "评估问题列表 (The List of Evaluation Questions)"
          ]
        },
        {
          "step": 2,
          "action": "设置状态标志",
          "details": "初始化两个全局状态标志，用于追踪关键事件：",
          "flags": [
            {
              "name": "actionA_triggered",
              "initialValue": false
            },
            {
              "name": "actionB_triggered",
              "initialValue": false
            },
            {
              "name": "contradiction_details",
              "initialValue": null,
              "purpose": "用于记录actionA中发现的真实矛盾"
            }
          ]
        }
      ]
    },
    {
      "stageId": 2,
      "stageName": "逐项分析‘评估问题’ (Iterative Analysis)",
      "description": "我将遍历‘评估问题列表’中的每一个‘评估问题’，并按顺序执行以下两个核心步骤。",
      "subSteps": [
        {
          "stepId": "2.1",
          "title": "评估问题的有效性分析 (Validity Analysis)",
          "objective": "判断‘评估问题’是否为原始‘问题’的有效子集。",
          "process": {
            "actions": [
              {
                "id": 1,
                "name": "约束比对",
                "details": "拆解当前‘评估问题’中的所有约束条件。"
              },
              {
                "id": 2,
                "name": "溯源检查",
                "details": "检查每一个约束条件是否能在原始‘问题’中找到明确的出处或逻辑上的直接对应。"
              }
            ],
            "outcomes": [
              {
                "case": "是有效子集",
                "judgement": "该‘评估问题’有效。",
                "action": "在报告中详细记录该‘评估问题’的每个约束条件在原始‘问题’中的具体来源。"
              },
              {
                "case": "不是有效子集",
                "judgement": "该‘评估问题’无效。",
                "action": "在报告中明确指出是哪个（或哪些）约束条件在原始‘问题’中找不到出处。",
                "subProcess": {
                  "condition": "如果‘评估问题’声称原始‘问题’存在矛盾",
                  "action": "我将独立分析原始‘问题’，判断这个声称的矛盾是否真实存在。",
                  "results": [
                    {
                      "condition": "矛盾真实存在",
                      "actionToExecute": "执行 actionA",
                      "effects": [
                        "设置 actionA_triggered = True",
                        "记录这个‘评估问题’和它指出的真实矛盾内容到 contradiction_details"
                      ]
                    },
                    {
                      "condition": "矛盾并不存在（评估问题捏造或误判了矛盾）",
                      "actionToExecute": "执行 actionB",
                      "effects": [
                        "设置 actionB_triggered = True"
                      ]
                    }
                  ]
                }
              }
            ]
          }
        },
        {
          "stepId": "2.2",
          "title": "模型回复的符合度判断 (Compliance Judgment)",
          "objective": "基于第一阶段的分析结果，判断‘模型回复’是否符合每个‘评估问题’的要求。",
          "details": "这是一个带有“短路机制”的判断流程，其逻辑严格依赖于actionA和actionB的状态。"
        }
      ]
    },
    {
      "stageId": 3,
      "stageName": "生成综合分析报告 (Final Report Synthesis)",
      "description": "在遍历完所有‘评估问题’后，我将根据记录的状态和分析结果，生成最终报告。",
      "adjudicationLogic": [
        {
          "logicId": 1,
          "condition": "如果 actionA_triggered 为 True",
          "summary": "这表示至少有一个‘评估问题’正确地指出了原始‘问题’中的一个真实矛盾。这是对模型最高难度的考验。",
          "coreCheckpoint": {
            "check": "‘模型回复’是否也指出了这个被contradiction_details记录的真实矛盾？",
            "outcomes": [
              {
                "condition": "‘模型回复’未能指出该矛盾",
                "conclusion": "模型未能通过核心考验。",
                "reportFormat": [
                  "对于那个正确指出矛盾的‘评估问题’，其结果标记为‘不符合’。",
                  "对于所有其他的‘评估问题’，无论其有效性如何，结果全部标记为‘不确定’。（因为模型在关键的第一步就失败了，后续的评估失去了意义）。"
                ],
                "endState": "任务结束，输出报告。"
              },
              {
                "condition": "‘模型回复’成功指出了该矛盾",
                "implicitLogic": "模型通过了核心考验。现在可以继续评估它在其他方面的表现。",
                "actions": [
                  "对该‘评估问题’标记为‘符合’。",
                  "然后，继续按照裁决逻辑3的流程处理剩余的‘评估问题’。"
                ]
              }
            ]
          }
        },
        {
          "logicId": 2,
          "condition": "如果 actionB_triggered 为 True (且 actionA_triggered 为 False)",
          "summary": "这表示至少有一个‘评估问题’错误地声称原始‘问题’存在矛盾。",
          "conclusion": "评估流程中存在无效的评估项，需要区别对待。",
          "reportFormat": [
            "对于所有触发了actionB的‘评估问题’（即捏造矛盾的评估问题），其结果标记为‘不确定’。（因为评估问题本身有误，无法基于它进行有效判断）。",
            "然后，继续按照裁决逻辑3的流程正常处理剩余的‘评估问题’。"
          ],
          "endState": "任务结束，输出报告。"
        },
        {
          "logicId": 3,
          "condition": "默认裁决流程 (如果 actionA 和 actionB 均未被触发)",
          "summary": "这是最标准的情况，所有‘评估问题’要么是有效子集，要么是无效但未声称矛盾。",
          "reportFormat": [
            "逐个判断‘模型回复’是否符合每一个被判定为有效的‘评估问题’的要求。",
            "若符合，标记为‘符合’。",
            "若不符合，标记为‘不符合’。",
            "对于所有在步骤2.1中被判定为无效的‘评估问题’（且未触发A或B），其结果标记为‘不确定’。"
          ],
          "endState": "任务结束，输出报告。"
        }
      ]
    }
  ],
  "summary": {
    "conclusion": "这个SOP将我的评估工作流程化、标准化，确保每一步都有据可循。",
    "logicLayers": [
      "评估问题自身的有效性 (Validity)",
      "是否触发特殊逻辑 (Contradiction Handling)",
      "模型回复对有效指令的遵循度 (Compliance)"
    ]
  }
}